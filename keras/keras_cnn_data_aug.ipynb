{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data augumentation using Keras\n",
    "on MNIST data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using plaidml.keras.backend backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keras version: 2.2.4.1\n",
      "keras backend: plaidml.keras.backend\n",
      "keras image format: channels_last\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#from tensorflow import keras\n",
    "import keras\n",
    "\n",
    "print('keras version:', keras.__version__)\n",
    "print('keras backend:', keras.backend.backend())\n",
    "print('keras image format:', keras.backend.image_data_format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = data.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (60000, 28, 28)\n",
      "train y: (60000,)\n",
      "test_shape: (10000, 28, 28)\n",
      "test y: (10000,)\n",
      "num of labels: 10\n",
      "image size: 28\n",
      "input shape: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# show information about the downloaded data\n",
    "\n",
    "print('train shape:', x_train.shape)\n",
    "print('train y:', y_train.shape)\n",
    "print('test_shape:', x_test.shape)\n",
    "print('test y:', y_test.shape)\n",
    "\n",
    "\n",
    "num_labels = len(np.unique(y_train))\n",
    "image_size = x_train.shape[2]\n",
    "\n",
    "print('num of labels:', num_labels)\n",
    "print('image size:', image_size)\n",
    "\n",
    "# calculate input shape and number of channels\n",
    "is_channels_first = (keras.backend.image_data_format() == 'channels_first')\n",
    "shape_len = len(x_train.shape)\n",
    "\n",
    "if shape_len == 3:\n",
    "    num_channels = 1\n",
    "else:\n",
    "    num_channels = 3\n",
    "\n",
    "if is_channels_first:\n",
    "    input_shape = (num_channels , image_szie , image_size)\n",
    "else:\n",
    "    input_shape = ( image_size , image_size , num_channels)\n",
    "\n",
    "print('input shape:', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the shape of data depending on the image data format\n",
    "\n",
    "if is_channels_first :\n",
    "    x_train2 = x_train.reshape(x_train.shape[0], num_channels, image_size, image_size)\n",
    "    x_test2 = x_test.reshape(x_test.shape[0], num_channels, image_size, image_size)\n",
    "else:\n",
    "    x_train2 = x_train.reshape(x_train.shape[0], image_size, image_size, num_channels)\n",
    "    x_test2 = x_test.reshape(x_test.shape[0], image_size, image_size, num_channels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the data: 0.0 to 1.0\n",
    "\n",
    "x_train2 = x_train2.astype('float32') / 255\n",
    "x_test2 = x_test2.astype('float32') / 255\n",
    "\n",
    "#hot encode\n",
    "y_train2 = keras.utils.to_categorical(y_train)\n",
    "y_test2 = keras.utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revised x_train shape: (60000, 28, 28, 1)\n",
      "revised y_train shape: (60000, 10)\n",
      "revised x_test shape: (10000, 28, 28, 1)\n",
      "revised y_test shape: (10000, 10)\n",
      "input shape: (28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# show info about reshaped data\n",
    "\n",
    "print(\"revised x_train shape:\", x_train2.shape)\n",
    "print('revised y_train shape:', y_train2.shape)\n",
    "print('revised x_test shape:', x_test2.shape)\n",
    "print('revised y_test shape:', y_test2.shape)\n",
    "print('input shape:',input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden dense layer size: 512\n"
     ]
    }
   ],
   "source": [
    "num_hidden_layers = 512\n",
    "\n",
    "print('hidden dense layer size:', num_hidden_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Opening device \"opencl_nvidia_quadro_p1000.0\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               819712    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 843,658\n",
      "Trainable params: 843,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model = keras.models.Sequential()\n",
    "model.add( keras.layers.Conv2D(32, kernel_size=(3,3), input_shape=input_shape , activation='relu' ))\n",
    "model.add( keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add( keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu' ))\n",
    "model.add( keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add( keras.layers.Dropout(0.5))\n",
    "\n",
    "model.add( keras.layers.Flatten())\n",
    "model.add( keras.layers.Dense(num_hidden_layers, activation='relu'))\n",
    "\n",
    "model.add( keras.layers.Dropout(0.5))\n",
    "model.add( keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# compile to model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# show summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "59776/60000 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.9210- ETA: 2s - loss: 0.2840 - acc: 0.911 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:plaidml:Analyzing Ops: 131 of 249 operations complete\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 18s 305us/step - loss: 0.2545 - acc: 0.9211 - val_loss: 0.0586 - val_acc: 0.9816\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0879 - acc: 0.9729 - val_loss: 0.0362 - val_acc: 0.9865\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 14s 233us/step - loss: 0.0650 - acc: 0.9793 - val_loss: 0.0308 - val_acc: 0.9890\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 14s 234us/step - loss: 0.0548 - acc: 0.9827 - val_loss: 0.0269 - val_acc: 0.9897\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 15s 244us/step - loss: 0.0488 - acc: 0.9845 - val_loss: 0.0274 - val_acc: 0.9899\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 14s 228us/step - loss: 0.0435 - acc: 0.9856 - val_loss: 0.0220 - val_acc: 0.9911\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 13s 219us/step - loss: 0.0391 - acc: 0.9875 - val_loss: 0.0225 - val_acc: 0.9923\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 13s 217us/step - loss: 0.0362 - acc: 0.9883 - val_loss: 0.0227 - val_acc: 0.9924\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 13s 221us/step - loss: 0.0341 - acc: 0.9891 - val_loss: 0.0211 - val_acc: 0.9921\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 14s 230us/step - loss: 0.0313 - acc: 0.9897 - val_loss: 0.0218 - val_acc: 0.9936\n"
     ]
    }
   ],
   "source": [
    "#train the model with train data for few runs to setup the weights\n",
    "\n",
    "fit_history = model.fit(x_train2, y_train2,\n",
    "epochs=10,\n",
    "batch_size=128,\n",
    "validation_data=(x_test2,y_test2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dirs to hold logs and models so you can review them later\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# helper function to create unique sub folder\n",
    "def create_folder(folder_name):\n",
    "    if (not os.path.exists(folder_name)):\n",
    "        os.makedirs(folder_name)\n",
    "    new_dir = folder_name + \"/{}\".format(time.time())\n",
    "    if (not os.path.exists(new_dir)):\n",
    "        os.makedirs(new_dir)\n",
    "    return new_dir\n",
    "\n",
    "log_dir = create_folder('logs')\n",
    "model_dir = create_folder('models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define how to save snapshots of model states during training\n",
    "checkpt_path=model_dir+'/va{val_acc:.5f}-ep{epoch:04d}-ac{acc:.5f}-vl{val_loss:.5f}-l{loss:.5f}.hdf5'\n",
    "cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "  checkpt_path ,\n",
    "  verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup to capture log so that you can view it from tensorflow dashboard\n",
    "# comment this out if you are NOT using tensorflow\n",
    "\n",
    "#import tensorflow as tf\n",
    "#tf_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use datagen to 'augument' the training data\n",
    "# tweak the parameters to get better results\n",
    "\n",
    "datagen = keras.preprocessing.image.ImageDataGenerator(\n",
    "  rotation_range = 25,\n",
    "  width_shift_range=0.10,\n",
    "  height_shift_range=0.10,\n",
    "  zoom_range = 0.10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size: 128\n",
      "epochs: 300\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "epochs = 300\n",
    "\n",
    "print('batch size:', batch_size)\n",
    "print('epochs:', epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "468/468 [==============================] - 27s 58ms/step - loss: 0.2161 - acc: 0.9344 - val_loss: 0.0247 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00001: saving model to models/1557955871.1748924/va0.99290-ep0001-ac0.93441-vl0.02472-l0.21615.hdf5\n",
      "Epoch 2/300\n",
      "468/468 [==============================] - 25s 54ms/step - loss: 0.1384 - acc: 0.9574 - val_loss: 0.0209 - val_acc: 0.9935\n",
      "\n",
      "Epoch 00002: saving model to models/1557955871.1748924/va0.99350-ep0002-ac0.95738-vl0.02088-l0.13839.hdf5\n",
      "Epoch 3/300\n",
      "468/468 [==============================] - 29s 63ms/step - loss: 0.1173 - acc: 0.9640 - val_loss: 0.0216 - val_acc: 0.9933\n",
      "\n",
      "Epoch 00003: saving model to models/1557955871.1748924/va0.99330-ep0003-ac0.96401-vl0.02159-l0.11729.hdf5\n",
      "Epoch 4/300\n",
      "468/468 [==============================] - 26s 55ms/step - loss: 0.1049 - acc: 0.9686 - val_loss: 0.0213 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00004: saving model to models/1557955871.1748924/va0.99260-ep0004-ac0.96858-vl0.02130-l0.10483.hdf5\n",
      "Epoch 5/300\n",
      " 57/468 [==>...........................] - ETA: 23s - loss: 0.1024 - acc: 0.9683 ETA: 22s - loss: 0.1131 - acc: 0. - ETA: 22s - loss - ETA: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-dc65ca4da315>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m   \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m   \u001b[1;31m#workers=4,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcp_callback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m )\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1431\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1432\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1433\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1435\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1230\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1231\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1232\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1233\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\plaidml\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\plaidml\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    176\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_invoker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ctx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36mas_ndarray\u001b[1;34m(self, ctx)\u001b[0m\n\u001b[0;32m   1228\u001b[0m                 \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdimensions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1229\u001b[0m                 dtype=_NP_TYPES[self.shape.dtype])\n\u001b[1;32m-> 1230\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmap_current\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1231\u001b[0m             \u001b[0mview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy_to_ndarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"generator didn't yield\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36mmmap_current\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmmap_current\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1212\u001b[0m         mapping = _lib().plaidml_map_buffer_current(self.buffer,\n\u001b[1;32m-> 1213\u001b[1;33m                                                     ctypes.cast(None, _MAP_BUFFER_FUNCTYPE), None)\n\u001b[0m\u001b[0;32m   1214\u001b[0m         yield _View(self.buffer._ctx, mapping, self.shape.dtype, self.shape.ctype,\n\u001b[0;32m   1215\u001b[0m                     _lib().plaidml_get_shape_element_count(self.shape), self.shape, None)\n",
      "\u001b[1;32mc:\\mysoftware\\python36\\lib\\site-packages\\plaidml\\__init__.py\u001b[0m in \u001b[0;36m_check_err\u001b[1;34m(self, result, func, args)\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaidml_compute_grad_wrt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrcheck\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_err\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# run data augumentation based training\n",
    "# add in tf_callback if using tensorflow so you can monitor the progress using tf dashboard\n",
    "\n",
    "fit_history2 = model.fit_generator(\n",
    "  datagen.flow(x_train2,y_train2,batch_size=batch_size),\n",
    "  steps_per_epoch = int(len(x_train2) / batch_size),\n",
    "  epochs = epochs,\n",
    "  validation_data = (x_test2, y_test2),\n",
    "  #workers=4, \n",
    "  callbacks=[cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
